---
title: "Data Workflow Best Practices"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

<br>

#### Overview
The workflow of test development is the transformation of raw data into published research results. This data workflow has three components:

1. __Input__: Raw data in .csv or .xlsx files.
2. __Process__: Computer code that operates on the data (i.e., reads the input, transforms and analyzes it, writes the output).
3. __Output__: Tables and graphs that display the results of data analysis, formatted to support print and digital publication.

This document describes the core principles of a _robust_ data workflow based on R, RStudio, and the tidyverse. Going forward, we will use the terms "method", "process", and "workflow" somewhat interchangeably. Here, "robustness" means something like "widely applicable, adaptable, and resilient against external sources of error and disruption." A robust process imposes stringent and specific requirements on it inputs, and allows equally rigorous definition of its outputs. But when the input conditions are satisfied, the robust process, _in its generic form_, consistently and reliably yields the required output.

In practice, this robust workflow can be automated and re-purposed across projects, minimizing start-up time, code customization, copying-and-pasting within scripts, and vulnerability to operator error. The robust process is supported by code templates, detailed documentation, and a set of work habits and guidelines for how data files are managed and shared among multiple users. 

The current document contains blocks of executable code, alongside extensive commentary. The narrative is organized into sections reflecting discrete topics and operations in the workflow. Each section has two parts:

1. `EXECUTABLE CODE`: this code can be copy-and-pasted into a working R script. Before running, make sure that all file paths are specified correctly for the local environment. __Note that all code in this document was written for the Mac OS; Windows typically requires the substitution of `\` for `/` in file paths.__
2. `COMMENTED SNIPPETS`: these snippets provide analysis and explanation of the code and workflow. The R code in these snippets is redundant with that in the `EXECUTABLE CODE` section. Here, it serves merely to enhance the documentation, and is not meant to be run.

This HTML document is sourced from (and can be updated with) an accompanying R Notebook.[^longnote]

[^longnote]:The HTML document is generated by an R Notebook markdown document (.rmd). To generate an updated version of the HTML document, render (knit) the Notebook into the RStudio Viewer Pane:

    * In RStudio Preferences, R Markdown section, set the `Show output preview in:` option to `Viewer Pane`.
    * Knit the notebook using `File -> Knit Document`. This will produce a readable HTML version of this document in the Viewer Pane. 
    * Close this Notebook (once you have the HTML in the Viewer, you no longer need the Notebook).
    * Open a new R script in the Source Pane. This will serve as your working script, into which you can copy-and-paste code from the HTML.

<br>

#### First things first: Create an RStudio project and standard folder structure
The robust workflow is based on the RStudio project folder structure. To set up a project in RStudio, click _File -> New Project_. Specify a top-level working directory associated with the project. Create the following folders within the working directory:

* `CODE`: R scripts (`*.R`)
* `DOCUMENTATION`: explanatory documents (`*.rmd`, `*.html`)
* `INPUT-FILES`: data to be processed by R scripts (`*.csv`)
* `OUTPUT-FILES`: saved output from R scripts (`*.csv`, `*.jpg`, `*.png`)

Within these folders, sub-folders will vary by project. There may also be other project-specific folders at the top level.
 
<br>

#### Install and load core packages
###### EXECUTABLE CODE
```{r core, eval = FALSE}
suppressMessages(library(here))
suppressMessages(suppressWarnings(library(tidyverse)))
```
Use `base::install.packages()` and `base::library()` to install and load the core packages for file path specification (`here`) and data wrangling (`tidyverse`). Use `base::suppressMessages()` and `base::suppressWarnings()` as needed to quiet chatter in the console.^[The double-colon `::` operator links a function to its parent package, as in `package::function()`. By using this elaborated specification in code, we can run an installed function without loading its entire parent library. 
Regardless, in code and accompanying commentary, a function name is always followed by a double-parenthesis wrapper `()`.]

`tidyverse` is a meta-package that contains the suite of libraries and functions required for implementing the robust data workflow described in this document.

`here::here()` anchors the file path to the top-level project folder. Thus, other users of the script need only replicate the standard project folder structure on their local machines, and read/write functions will run without error.

The next snippet demonstrates the use of `here()` to read an input file (with `readr::read_csv()`, which is included in the `tidyverse` package):
```
input <- read_csv(here("INPUT-FILES/data.csv"))
```
Note that the file path is enclosed in double-quotes, and it _does not_ begin with a leading `/`.

<br>

#### Robust templates: Tokenization of project-specific elements

###### EXECUTABLE CODE
```{r token, eval = FALSE}
urlRemote_path  <- "https://raw.github.com/"
github_path <- "wpspublish/DSHerzberg-RATING-SCALE-ANALYSIS/master/INPUT-FILES/"
input_name <- "data-RS-sim-child-parent.csv"

item_prefix <- "cp"
scale_prefix <- "CP"
scale_suffix <- c("S1", "S2", "S3", "S4", "S5", "TOT")
age_range_name <- "child"
form_name <- "parent"
all_raw_range <- 10:200
TOT_raw_lower_bound <- 50
subscale_raw_upper_bound <- 40
t_score_lower_bound <- 40
t_score_upper_bound <- 80

assign(str_c("data", age_range_name, form_name, sep = "_"),
       suppressMessages(read_csv(url(
         str_c(urlRemote_path, github_path, input_name)
       ))))
```

<br>

###### COMMENTED SNIPPETS

##### Object and variable names in R

When R boots up, it opens a workspace, or programming environment, in local memory. The environment contains _objects_, or data elements (e.g., vectors, data frames, lists, etc.). Each object has a unique name that allows it to be referenced by code.

Our robust data workflow operates in this programming environment.^[Actually, many discrete environments may exist within the R workspace. In general our data objects are contained in the most general and inclusive of these: the _global environment_.] The workflow's _process_ component consists of R code that manipulates named data objects. By reading the _input_ components of the workflow, we initialize them as named input objects in the R environment. Thus, the input components now exist in local memory, in addition to being saved files in some other location. Applying code, we transform input objects into named output objects, which also reside in local memory. We complete the process by writing the output objects to external files (saved elsewhere), where they become the _output_ components of the data workflow.

Clearly, names are an important feature of the workflow. R provides naming functions that allow us to assemble and manipulate names to support the robustness of our code. More on this in a moment.

Names exist in a two-level hierarchy in R:

1. Named data objects in the programming environment;
2. Variable (column) names _within_ those data objects.

We create object names in our code, and we can modify the variable names that exist within the data objects.

To create code that is coherent, readable and aligned with the general nomenclature of the project, names should either be identical to, or closely related to the names present in the raw data files (the input components of the data workflow).

In raw data files, names exist on the level of files and folders, and also on the level of variables. These names belong to a class of _project-specific_ data elements. Consider the differences between two projects: a parent interview for adaptive behavior, and an ADHD-focused rating scale. These two projects will have different file names, variable names, and so on.

These differences embody the challenge of developing code templates to support a robust data workflow. To ensure robustness, the templates must be able to handle the input components of different projects with little or no code customization. Yet the need to manipulate project-specific data elements often demands code customization, not to mention extensive copying-and-pasting of names throughout scripts.

Robustness therefore depends on two key name-handling features. We need to be able to:

1. Enter the project-specific names only once, and have those names flow automatically throughout the entire script.
2. Assemble complex names that combine two or more project-specific elements.

To satisfy the first requirement, we initialize _tokens_ at the head of the code template. A token contains an element of data (usually a name) that is processed by the code at least once (but usually several times). Examples of tokens include names of variables, files, folders, test forms, raters, etc., as well as labels for age and score ranges, score item counts, numerical bounds, and so forth. 

A complete set of tokens therefore encompasses all of the project-specific names that we need to manipulate in the ensuing script. The remainder of the template is primarily _project-general_ code, consisting of those functions and operations whose specification is identical for all projects For example, creating a table of descriptive statistics requires calling the same set of functions, regardless of whether the input data are from the adaptive behavior parent interview or the ADHD rating scale. In this way, the process component of the robust data workflow is the execution of project-general functions that refer to project-specific tokens.

##### Naming methods

R offers several methods for creating names and assigning them to objects and variables. The most common way is to use the assignment operator `<-`, which creates a data object in the R programming environment and assigns a name to it. We can use the assignment operator to initialize tokens, which are usually represented in R as _vectors_, a certain type of data object. 

For example, the first line of the next snippet is `urlRemote_path  <- "https://raw.githubusercontent.com/"`, which creates the token `urlRemote_path`, a vector whose sole element is the string `"https://raw.githubusercontent.com/"`. When initializing a vector that contains more than one string element, we wrap the elements in the combine function `base::c()`, as in `scale_suffix <- c("S1", "S2", "S3", "S4", "S5", "TOT")`.

```{r token, echo = 1:15, eval = F}
```
The assignment operator works well for creating simple names that are themselves _explicit_ strings (e.g., "item_prefix", "scale_prefix", etc. in the previous snippet). However recall from the earlier discussion that we often need to assemble complex names consisting of two or more project-specific elements. These complex names are _concatenated_ strings (i.e., single strings resulting from the combination of several parts). We use R's suite of concatenating functions to join explicit strings and previously defined tokens into new complex names.

The assignment operator cannot be used to create complex names. Instead, we use `base::assign()`, which takes two arguments: The desired name (concatenated with `stringr::str_c()` or another string function), and the expression that defines the object(s) to be named.

In the example below, we use `assign()` to name an input data file read in by `readr::read_csv()`. The first argument, `str_c("data", age_range_name, form_name, sep = "_")`, returns the name `data_child_parent`, combining the file type description (`"data"`, provided as an explicit string) with the age-range (`age_range_name`) and rater (`form_name`) tokens. The combination of these latter two tokens identifies the form whose data is contained in the input file. The last argument to `str_c()` is `sep = "_"`, which indicates that in the returned name, the concatenated elements will be separated by underscores.

The second argument to `assign()` specifies the data object to be named with the concatenated string. Here, an object is created by reading the input data file with `read_csv()`. Note how the input file path is itself a concatenation of three previously defined tokens `str_c(urlRemote_path, github_path, input_name)`.
```{r token, echo = 16:19, eval = F}
```
`str_c()` is also useful in creating tokens that are sets of project-specific elements. For example, we often need to refer to the entire set of item names, or the entire set of form names. To assemble these sets, we need to specify names on two levels: the name of the set (the token name), and the names of the elements within the set.

Often, the desired set element names are numerically sequenced (e.g., the set of item names). In these instances, we can use `str_c()` to combine a prefix (represented as a token or an explicit string) with a vector containing the desired numerical sequence. For example,
```
prefix <- "i"
items <- str_c(prefix, c("001", "002", "003"), sep = "_")
```
returns a token (vector) that is a set of item names. The token is named `items`, and the item names are `"i_001" "i_002" "i_003"`. This operation takes advantage of the fact that R "recycles" vectors. In other words, `str_c()` combines the first argument (the token `prefix`) with the second argument (a three-element vector of numbers) over the entire length of the second argument, yielding a three-element vector as its output.

<br>

#### Input requirements: File-naming conventions (work in progress)

File name example:

```
"tod-data-stand-amk.csv"
```


The robust data workflow requires standardization of the names of .csv and .xlsx files that contain raw data. Some ground rules:

* Within R code, references to external file paths and saved files are always enclosed in double quotes `""`
* File names SHOULD NOT contain:
    + blank spaces (replace with hyphens `-`)
    + any other non-alphanumeri characters (besides hyphens)
    + upper-case letters
* Names of persons should be expressed as lower-case three-letter acronyms
    
Thus, we use `"jfd-project-data.csv"`, and NOT `John Doe's Project Data.csv`.

When reading files into R, we may need to take into account folder and file structures set up to facilitate manual entry of data from printed test forms. When multiple operators are working on the same project, they may save their work in distinct MS Excel files, on their local machines or in their own folders on the organization's network.

Each operator may then create several different .xlsx files to differentiate (for example) data from clinical cases, typically developing children, a test-retest cohort, and so on. And, within an .xlsx file, there may be multiple worksheets (tabs) to subdivide data within cases. For example, there may be separate sheets for demographic information, responses from the test under development, responses from concurrently administered measures, and so on.

What's important to note is that each of these different ways of dividing up the data (which are implemented to facilite data entry) represent information that we typically want to preserve and make available for analysis. For example, we might want to compare the data entered by different operators. To do this, we would need to create a variable (column) where each case would receive a code indicating the operator who entered that case. But the information required to assign values in that column many not be represented explicitly in the .xlsx sheets themselves. In fact, it may be represented in a folder structure, which is not a format that we can analyze with a statistical package.

Here is where the file naming, in combination with tokenization, becomes useful. We can represent two levels of differentiation in the file name. Suppose we have two operators, John Frederick Doe, and Jane Maria Roe; and two data sources, typical and clinical. We can tokenize these variables as follows:

```
operator <- c("jfd", "jmr")
data_source <- c("clinical", "typical")
```

And we would name data files accordingly:

```
"strat1-strat2-project_name-data.csv"
```

<br>

#### Input requirements: Variable-naming conventions (work in progress)

<br>

#### Date-Time formats
