---
title: "Data Workflow Best Practices"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

<br>

#### Overview
The workflow of test development is the transformation of raw data into published research results. This data workflow has three components:

1. __Input__: Raw data in .csv or .xlsx files.
2. __Process__: Computer code that operates on the data (i.e., reads the input, transforms and analyzes it, writes the output).
3. __Output__: Tables and graphs that display the results of data analysis, formatted to support print and digital publication.

This document describes the core principles of a _robust_ data workflow based on R, RStudio, and the tidyverse. Going forward, we will use the terms "method", "process", and "workflow" somewhat interchangeably. Here, "robustness" means something like "widely applicable, adaptable, and resilient against external sources of error and disruption." A robust process imposes stringent and specific requirements on it inputs, and allows equally rigorous definition of its outputs. But, if the input conditions are satisfied, the robust process, _in its generic form_, consistently and reliably yields the required output.

In practice, this robust workflow can be automated and re-purposed across projects, minimizing start-up time, code customization, copying-and-pasting within scripts, and vulnerability to operator error. The robust process is supported by code templates, detailed documentation, and a set of work habits and guidelines for how data files are managed and shared among multiple users. 

The document contains blocks of executable code, alongside extensive commentary. The narrative is organized into sections reflecting discrete topics and operations in the workflow. Each section has two parts:

1. `EXECUTABLE CODE`: this code can be copy-and-pasted into a working R script. Before running, make sure that all file paths are specified correctly for your local environment. __Note that all code in this document was written for the Mac OS, so if you are working in Windows, you may need to substitute `\` for `/` in file paths.__
2. `COMMENTED SNIPPETS`: these snippets provide analysis and explanation of the code and workflow. The R code in these snippets is redundant with that in the `EXECUTABLE CODE` section. Here, it serves merely to enhance the documentation, and is not meant to be run.

This HTML document is sourced from (and can be updated with) an accompanying R Notebook.[^longnote]

[^longnote]:The HTML document is generated by an R Notebook markdown document (.rmd). To generate an updated version of the HTML document, render (knit) the Notebook into the RStudio Viewer Pane:

    * In RStudio Preferences, R Markdown section, set the `Show output preview in:` option to `Viewer Pane`.
    * Knit the notebook using `File -> Knit Document`. This will produce a readable HTML version of this document in the Viewer Pane. 
    * Close this Notebook (once you have the HTML in the Viewer, you no longer need the Notebook).
    * Open a new R script in the Source Pane. This will serve as your working script, into which you can copy-and-paste code from the HTML.

<br>

#### First things first: Create an RStudio project and standard folder structure
The robust workflow is based on the RStudio project folder structure. We can set up a project in RStudio by clicking _File -> New Project_. Specify a top-level working directory associated with the project. Create the following folders within the working directory:

* `CODE`: R scripts (`*.R`)
* `DOCUMENTATION`: explanatory documents (`*.rmd`, `*.html`)
* `INPUT-FILES`: data to be processed by R scripts (`*.csv`)
* `OUTPUT-FILES`: saved output from R scripts (`*.csv`, `*.jpg`, `*.png`)

Within these folders, sub-folders will vary by project. There may also be other project-specific folders at the top level.
 
<br>

#### Install and load core packages
###### EXECUTABLE CODE
```{r core, eval = FALSE}
suppressMessages(library(here))
suppressMessages(suppressWarnings(library(tidyverse)))
```
Use `base::install.packages()` and `base::library()` to install and load the core packages for file path specification (`here`) and data wrangling (`tidyverse`). Use `base::suppressMessages()` and `base::suppressWarnings()` as needed to quiet chatter in the console.^[The double-colon `::` operator links a function to its parent package, as in `package::function()`. By using this elaborated specification in code, we can run an installed function without loading its entire parent library. 
Regardless, in code and accompanying commentary, a function name is always followed by a double-parenthesis wrapper `()`.]

`tidyverse` is a meta-package that contains the suite of libraries and functions required for implementing the robust data workflow described in this document.

`here::here()` anchors the file path to the top-level project folder. Thus, other users of the script need only replicate the standard project folder structure on their local machines, and read/write functions will run without error.

The next snippet demonstrates the use of `here()` to read an input file (with `readr::read_csv()`, which is included in the `tidyverse` package):
```
input <- read_csv(here("INPUT-FILES/data.csv"))
```
Note that the file path is enclosed in double-quotes, and it _does not_ begin with a leading `/`.

<br>

#### Robust templates: Tokenization of project-specific elements

###### EXECUTABLE CODE
```{r token, eval = FALSE}
urlRemote_path  <- "https://raw.githubusercontent.com/"
github_path <- "DSHerzberg/RATING-SCALE-ANALYSIS/master/INPUT-FILES/"
input_name <- "data-RS-sim-child-parent.csv"

item_prefix <- "cp"
scale_prefix <- "CP"
scale_suffix <- c("S1", "S2", "S3", "S4", "S5", "TOT")
age_range_name <- "child"
form_name <- "parent"
all_raw_range <- 10:200
TOT_raw_lower_bound <- 50
subscale_raw_upper_bound <- 40
t_score_lower_bound <- 40
t_score_upper_bound <- 80

assign(str_c("data", age_range_name, form_name, sep = "_"),
       suppressMessages(read_csv(url(
         str_c(urlRemote_path, github_path, input_name)
       ))))
```

<br>

###### COMMENTED SNIPPETS
Robust code templates can be adapted to different projects with minimal sustitution and copying-and-pasting of text. Robust templates are characterized by their liberal use of _tokens_, which are names for _project-specific_ data and text elements that are used repeatedly throughout the template.

These tokenized elements include names of variables, files, test forms, raters, etc., as well as labels for age- and score ranges, score item counts and numerical bounds, and so forth. By definition, these elements differ between, say, an autism rating-scale project and an ADHD rating-scale project. 

In contrast, the _project-general_ aspects of an R script are those functions and operations whose specification is identical for all projects (e.g., creating a table of descriptive statistics requires calling the same set of functions, regardless of whether the input data are from the autism rating scale or the ADHD rating scale). In a robust template, tokens representing project-specific elements are defined at the head of the script. The remainder of the script, therefore, consists only of project-general code.

In R, we initialize tokens as _vectors_, using the the assignment operator `<-`. In the next code snippet, for example, `item_prefix <- "cp"` defines a vector that holds a prefix used in the names of all columns containing item responses. The snippet begins with three tokens that, when used together, specify the file path to a certain input file located on a certain remote URL.
```{r token, echo = 1:15, eval = F}
```
Many analytic procedures require the specification of an entire set of project-specific elements, such as the entire set of item names, or form names. We can use string functions to combine tokens and explicit text as needed, both to create the names of the elements within the set, and to create the accompanying token names. For instance, we can assemble a vector containing all of the item names by concatenating the token `item_prefix` with a numerical series (e.g., `c("001", "002", "003")`). 

Often, we want to name objects by combining previously defined tokens with explicit strings. To use a concatenated string as the name of an object in R, we cannot rely on the conventional assignment operator `<-`. Instead, we use `base::assign()` to initialize these concatenated names. `assign()` takes two arguments, the desired token name (concatenated with `stringr::str_c()`), and the code snippet that defines the object(s) to be named.

In the example below, we use `assign()` to name an input data file read in by `readr::read_csv()`. The first argument, `str_c("data", age_range_name, form_name, sep = "_")`, returns the name `data_child_parent`, combining the file type description (`"data"`, provided as an explicit string) with the age-range (`age_range_name`) and rater (`form_name`) tokens. The combination of these latter two tokens identifies the form whose data is contained in the input file. The last argument to `str_c()` is `sep = "_"`, which indicates that in the returned name, the concatenated elements will be separated by an underscore.

The second argument to `assign()` specifies the data object to be named with the concatenated string. Here, an object is created by reading the input data file with `read_csv()`. Note how the input file path is a concatenation of three previously defined tokens `str_c(urlRemote_path, github_path, input_name)`.
```{r token, echo = 16:19, eval = F}
```

<br>

#### Input requirements: File-naming conventions (work in progress)

The robust data workflow requires standardization of the names of .csv and .xlsx files that contain raw data. Some ground rules:

* Within R code, references to external file paths and saved files are always enclosed in double quotes `""`
* File names SHOULD NOT contain:
    + blank spaces (replace with hyphens `-`)
    + any other non-alphanumeri characters (besides hyphens)
    + upper-case letters
* Names of persons should be expressed as lower-case three-letter acronyms
    
Thus, we write `"jfd-project-data.csv"`, and NOT `John Doe's Project Data.csv`.

When reading files into R, we may need to take into account the structure set up to facilitate data entry. For example, if three different operators are entering raw data from printed forms into MS Excel, they may be saving their work in three different locations, on their local machines, the organization's network, and/or the cloud.

Within the different folders of the operators, there may be several different .xlsx files to differentiate (for example) data from clinical cases, typically developing children, a test-retest cohort, and so on. And, within an .xlsx file, there may be multiple worksheets (tabs) to organize the data from each case. For example, there may be separate sheets for demographic information, responses from the test being developed, responses from concurrently administered measures, and so on.

What's important to note is that each of these different ways of dividing up the data (which are implemented to facilite data entry) represent information that we typically want to preserve and make available for analysis. To use a less-obvious example, we might want to compare the data entered by different operators. To do this, we would need to create a variable (column) where each case would receive a code indicating the operator who entered that case. But the information required to assign values in that column many not be represented explicitly in the .xlsx sheets themselves. In fact, it may be represented in a folder structure, which is not a format that we can analyze with a statistical package.

Here is where the file naming, in combination with tokenization, becomes useful. We can represent two levels of differentiation in the file name. For example, let's suppose we have two operators, John Frederick Doe, and Jane Maria Roe; and two data sources, typical and clinical. We can tokenize these variables as follows:

```
operator <- c("jfd", "jmr")
data_source <- c("clinical", "typical")
```

And we would name data files accordingly:

```
"strat1-strat2-project_name-data.csv"
```

<br>

#### Input requirements: Varialbe-naming conventions (work in progress)

